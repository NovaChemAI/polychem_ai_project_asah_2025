# -*- coding: utf-8 -*-
"""Kaggle_Alternatif2_EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xx0RhQ6OmJE_ZOy46y-f4z2wXTRGIZuc
"""

!pip install  kagglehub

# Import Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub
import os

from sklearn.preprocessing import StandardScaler, LabelEncoder

# Load Dataset

# Download dataset
path = kagglehub.dataset_download("linyeping/extra-dataset-with-smilestgpidpolimers-class")

print("Dataset downloaded to:", path)

# Lihat isi folder
print(os.listdir(path))

# pilih file CSV paling besar
csv_files = [f for f in os.listdir(path) if f.endswith(".csv")]

files_with_size = [(f, os.path.getsize(os.path.join(path, f))) for f in csv_files]
files_sorted = sorted(files_with_size, key=lambda x: x[1], reverse=True)

main_csv = files_sorted[0][0]
file_path = os.path.join(path, main_csv)

df = pd.read_csv(file_path)

"""Overview Data"""

df.head(20)

df.info()

df.describe()

df.shape

df.dtypes

"""Data Cleaning"""

# Identifikasi Tipe Data
numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns
cat_cols = df.select_dtypes(include=["object"]).columns

# Mengecek missing value
df.isnull().sum()

# Cek dan hapus duplikat
df.duplicated().sum()
df = df.drop_duplicates()

"""Exploratory Data Analysis"""

# Distribusi data numerik
for col in numeric_cols:
    plt.figure()
    sns.histplot(df[col], kde=True)
    plt.title(f"Distribusi {col}")
    plt.show()

# Koleras antara variabel
plt.figure(figsize=(10,7))
sns.heatmap(df[numeric_cols].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Korelasi Antar Fitur Numerik")
plt.show()

# Hubungan antar fitur
sns.pairplot(df[numeric_cols], diag_kind="kde")
plt.show()

"""Normalisasi Data"""

# Encoding fitur kategori
le = LabelEncoder()
for col in cat_cols:
    df[col] = le.fit_transform(df[col])

scaler = StandardScaler()
df_scaled = df.copy()

df_scaled[numeric_cols] = scaler.fit_transform(df[numeric_cols])

df_scaled.head(50)

# simpan Dataset yang sudah bersih
df_scaled.to_csv("EDA_polymers_dataset_alternatif2.csv", index=False)